{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../local/az_reduced_reviews.csv')\n",
    "az_biz = pd.read_csv('../local/az_biz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = df[df.stars != 3]\n",
    "#ignore warning\n",
    "x_df['binary_stars'] =  np.where(x_df['stars'] >= 4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df.text, x_df.binary_stars, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick pipeline to show best performing nb\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', min_df=5, ngram_range=(2, 2))),\n",
    "                     ('tfidf', TfidfTransformer()),  \n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "#90.61% accurate - w/o stopword filter\n",
    "#90.80% accurate stop_words='english'\n",
    "#91.96% accurate CountVectorizer(stop_words='english', min_df=5)\n",
    "#93.31% accurate  CountVectorizer(stop_words='english', min_df=5, ngram_range=(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick pipeline to show best performing svm\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                         ('tfidf', TfidfTransformer()), \n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                        ])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "np.mean(predicted_svm == y_test)\n",
    "# 89.266% accurate\n",
    "# 87.47% accurate stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize the vocab\n",
    "count_vect = CountVectorizer(stop_words='english', min_df=5)\n",
    "X_train_vec = CountVectorizer(stop_words='english', min_df=5).fit(X_train)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = CountVectorizer(stop_words='english', min_df=5).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf the vectorized corpus\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a NB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the top indicating positive and negative terms\n",
    "linear_weights = nb.feature_log_prob_[1,] - nb.feature_log_prob_[0,]  # populate this with actual values\n",
    "\n",
    "top_negative_features= np.argsort(linear_weights)[0:10]\n",
    "top_positive_features= np.argsort(linear_weights)[-10:]\n",
    "\n",
    "print(\"Most negative features:\")\n",
    "for idx in top_negative_features:\n",
    "    for k, v in X_train_vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "            print(\"  {:s} ({:.02f})\".format(k, linear_weights[idx]))\n",
    "            \n",
    "print(\"\")\n",
    "print(\"Most positive features:\")\n",
    "for idx in top_positive_features:\n",
    "    for k, v in X_train_vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "            print(\"  {:s} ({:.02f})\".format(k, linear_weights[v]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb.feature_log_prob_.shape\n",
    "# X_train_vec.vocabulary_.get('best')\n",
    "idx = list(X_train_vec.vocabulary_.keys()).index('scraggly')\n",
    "# nb.feature_log_prob_[1,][idx] - nb.feature_log_prob_[0,][idx]\n",
    "print(idx)\n",
    "# linear_weights[112533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_features= np.argsort(linear_weights)[-1000:]\n",
    "nb_score_dict = {}\n",
    "\n",
    "# print(\"Most positive features:\")\n",
    "for idx in top_positive_features:\n",
    "    for k, v in X_train_vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "#             print(\"  {:s} ({:.02f})\".format(k, linear_weights[v]))\n",
    "            nb_score_dict[k] =linear_weights[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_score_dict = {}\n",
    "for k, v in X_train_vec.vocabulary_.items():\n",
    "        if k in word2tfidf.keys():\n",
    "            nb_score_dict[k] = linear_weights[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view az data by business with most reviews\n",
    "az_biz.sort_values('review_count', ascending=False)\n",
    "# pSQFynH1VxkfSmehRXlZWw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative features:\n",
      "  rude (-1.66)\n",
      "  overrated (-1.50)\n",
      "  worst (-1.39)\n",
      "  burned (-1.36)\n",
      "  mediocre (-1.34)\n",
      "  attitude (-1.26)\n",
      "  overpriced (-1.25)\n",
      "  disappointment (-1.24)\n",
      "  tasteless (-1.20)\n",
      "  average pizza (-1.18)\n",
      "\n",
      "Most positive features:\n",
      "  margherita (1.73)\n",
      "  excellent (1.74)\n",
      "  loved (1.86)\n",
      "  fresh (1.86)\n",
      "  rosa (1.88)\n",
      "  favorite (1.90)\n",
      "  amazing (1.95)\n",
      "  fantastic (1.96)\n",
      "  perfect (2.10)\n",
      "  delicious (2.23)\n"
     ]
    }
   ],
   "source": [
    "#run the same pipeline on a single business\n",
    "single_business = x_df[x_df['business_id'] == 'pSQFynH1VxkfSmehRXlZWw']\n",
    "sb_x = single_business['text']\n",
    "y_sb = single_business['binary_stars']\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english', min_df=2, ngram_range=(1, 2))\n",
    "sb_xtrain_vec = CountVectorizer(stop_words='english', min_df=2, ngram_range=(1, 2)).fit(sb_x)\n",
    "sb_xtrain_counts = count_vect.fit_transform(sb_x)\n",
    "sb_xtrain_counts.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sb_xtrain_tfidf = tfidf_transformer.fit_transform(sb_xtrain_counts)\n",
    "sb_xtrain_tfidf.shape\n",
    "\n",
    "nb_sb = MultinomialNB()\n",
    "nb_sb.fit(sb_xtrain_tfidf, y_sb)\n",
    "\n",
    "linear_weights_sb = nb_sb.feature_log_prob_[1,] - nb_sb.feature_log_prob_[0,]  # populate this with actual values\n",
    "\n",
    "top_negative_features= np.argsort(linear_weights_sb)[0:10]\n",
    "top_positive_features= np.argsort(linear_weights_sb)[-10:]\n",
    "\n",
    "print(\"Most negative features:\")\n",
    "for idx in top_negative_features:\n",
    "    for k, v in sb_xtrain_vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "            print(\"  {:s} ({:.02f})\".format(k, linear_weights_sb[v]))\n",
    "            \n",
    "print(\"\")\n",
    "print(\"Most positive features:\")\n",
    "for idx in top_positive_features:\n",
    "    for k, v in sb_xtrain_vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "            print(\"  {:s} ({:.02f})\".format(k, linear_weights_sb[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_weights_sb)\n",
    "sb_xtrain_vec.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_weights_sb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awesome', -0.8684038252389534),\n",
       " ('wonderful', -0.8115467990149252),\n",
       " ('excellent', -0.642301060147072),\n",
       " ('fantastic', -0.6189137928947295),\n",
       " ('perfect', -0.5692198201260341),\n",
       " ('amazing', -0.5395674559482213),\n",
       " ('delicious', -0.42350316877795),\n",
       " ('loved', -0.18473832061680717),\n",
       " ('love', -0.17753473442383694),\n",
       " ('favorite', -0.12668457492905727),\n",
       " ('pistachios', -0.08242755909203581),\n",
       " ('great', -0.07340085367247262),\n",
       " ('enjoyed', -0.05390112384602652),\n",
       " ('tasty', -0.0514100613361812),\n",
       " ('best', 0.0025272868358445777),\n",
       " ('atmosphere', 0.07825571784247654),\n",
       " ('biancoverde', 0.13165065149458854),\n",
       " ('arugula', 0.4002855932547664),\n",
       " ('fresh', 0.45694293096775596),\n",
       " ('sonny', 0.5595678051335291),\n",
       " ('margherita', 0.8879465223813199),\n",
       " ('prepared', 0.9005807505051298),\n",
       " ('mozzarella', 0.9354058078367284),\n",
       " ('wise', 1.3724854519063552),\n",
       " ('rosa', 1.3969290621870503)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 30\n",
    "diff_dict = {}\n",
    "top_n_positive_features= np.argsort(linear_weights_sb)[-n:]\n",
    "\n",
    "for idx in top_n_positive_features:\n",
    "    for a, b in sb_xtrain_vec.vocabulary_.items(): \n",
    "        if b == idx:\n",
    "            for j, k in X_train_vec.vocabulary_.items():\n",
    "                if j == a:\n",
    "                    diff = linear_weights_sb[b]- linear_weights[k]\n",
    "                    diff_dict[j] = diff\n",
    "        #                 print(j, diff)\n",
    "        \n",
    "import operator\n",
    "sorted_diff_dict = sorted(diff_dict.items(), key=operator.itemgetter(1))\n",
    "sorted_diff_dict[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_diff_dict = sorted(diff_dict.items(), key=operator.itemgetter(1))\n",
    "sorted_diff_dict[-25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_weights)\n",
    "# linear_weights[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the same pipeline on a single business\n",
    "single_business = x_df[(x_df['business_id'] == 'pSQFynH1VxkfSmehRXlZWw')]\n",
    "sb_x = single_business['text']\n",
    "y_sb = single_business['binary_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "sb_cv = cv.fit_transform(sb_x)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(sb_cv)\n",
    "word2tfidf = dict(zip(cv.get_feature_names(), tfidf_transformer.idf_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.asarray(tfidf_matrix.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_score_dict\n",
    "\n",
    "# pd.DataFrame(nb_score_dict.items(), columns=['term', 'score'])\n",
    "\n",
    "s = pd.Series(nb_score_dict, name='score')\n",
    "s.index.name = 'term'\n",
    "s.reset_index()\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df = pd.DataFrame(list(nb_score_dict.items()), columns=['term', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_out = pd.merge(weights_df, nb_df, on='term', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_out['polarity'] = biz_out['weight'] * biz_out['score']\n",
    "biz_out.sort_values(by='weight', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_dict = {}\n",
    "    \n",
    "for word, score in word2tfidf.items():\n",
    "    polarity_score = nb_score_dict.get(word, 0) * score\n",
    "    polarity_dict[word] = polarity_score\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_polarity_dict = sorted(polarity_dict.items(), key=operator.itemgetter(1))\n",
    "sorted_polarity_dict[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2tfidf.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.vocabulary_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2tfidf.get('margerhita')\n",
    "X_train_vec.vocabulary_.get('margerhita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_score_dict = {}\n",
    "for idx in linear_weights:\n",
    "    if idx > 0:\n",
    "        for k, v in X_train_vec.vocabulary_.items():\n",
    "            if v == idx:\n",
    "                nb_score[k] = linear_weights[v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "top_corpus_features= np.argsort(linear_weights)[-n:]\n",
    "\n",
    "\n",
    "polarity_dict = {}\n",
    "\n",
    "for idx in top_corpus_features:\n",
    "    for word, score in word2tfidf.items():\n",
    "        if score > 0:\n",
    "            for j, k in X_train_vec.vocabulary_.items():\n",
    "                if j == word:\n",
    "                    polarity_score = k * score\n",
    "                    polarity_dict[word] = polarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_dict = {}\n",
    "\n",
    "for word, score in word2tfidf.items():\n",
    "    if score > 0:\n",
    "        for j, k in X_train_vec.vocabulary_.items():\n",
    "            if j == word:\n",
    "                polarity_score = k * score\n",
    "                polarity_dict[word] = polarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_vec.vocabulary_)\n",
    "len(linear_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice area below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_biz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in top_positive_features:\n",
    "    for k, v in vec.vocabulary_.items():\n",
    "        if v == idx:\n",
    "            print(k)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
